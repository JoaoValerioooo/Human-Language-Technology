{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LXucmalIYk"
      },
      "source": [
        "## Students:\n",
        "1.   João Valério\n",
        "2.   Eirik Grytøyr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV4ayENcxNeV",
        "outputId": "b9899573-1835-4c97-f848-7674bbe5d15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Getting the file STS.input.SMTeuroparl.txt from drive into a DataFrame\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "dt = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4xWDSCAD0mZ_"
      },
      "outputs": [],
      "source": [
        "# Updating the DataFrame with a new column with STS.gs.SMTeuroparl.txt\n",
        "dt['gs'] = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbsij6GJWNtA",
        "outputId": "140db684-86d6-45ff-82aa-36f7f897515a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "# Getting a list of stop words\n",
        "nltk.download('stopwords')\n",
        "stopWordSet = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def cleaner (sentenceList):\n",
        "\n",
        "  # Get the list into lowercase\n",
        "  sentenceList = list(map(lambda word: word.lower(), sentenceList))\n",
        "  \n",
        "  # Filtering the ponctuation and the stop words\n",
        "  sentenceList = list(filter(lambda word : re.search('''[!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~]+''', word) == None and word not in stopWordSet, sentenceList))\n",
        "  \n",
        "  return sentenceList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97XlHnj5Mlfa",
        "outputId": "5918e585-87a1-419f-8371-930b2d6f5f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Mapping the tags between Treebank and WordNet\n",
        "tag_map = {\n",
        "  'CC':\"none\", # coordin. conjunction (and, but, or)  \n",
        "  'CD':\"n\", # cardinal number (one, two)             \n",
        "  'DT':\"none\", # determiner (a, the)                    \n",
        "  'EX':\"r\", # existential ‘there’ (there)           \n",
        "  'FW':\"none\", # foreign word (mea culpa)             \n",
        "  'IN':\"r\", # preposition/sub-conj (of, in, by)   \n",
        "  'JJ':\"a\", # adjective (yellow)                  \n",
        "  'JJR':\"a\", # adj., comparative (bigger)          \n",
        "  'JJS':\"a\", # adj., superlative (wildest)           \n",
        "  'LS':\"none\", # list item marker (1, 2, One)          \n",
        "  'MD':\"none\", # modal (can, should)                    \n",
        "  'NN':\"n\", # noun, sing. or mass (llama)          \n",
        "  'NNS':\"n\", # noun, plural (llamas)                  \n",
        "  'NNP':\"n\", # proper noun, sing. (IBM)              \n",
        "  'NNPS':\"n\", # proper noun, plural (Carolinas)\n",
        "  'PDT':\"a\", # predeterminer (all, both)            \n",
        "  'POS':\"none\", # possessive ending (’s )               \n",
        "  'PRP':\"none\", # personal pronoun (I, you, he)     \n",
        "  'PRP$':\"none\", # possessive pronoun (your, one’s)    \n",
        "  'RB':\"r\", # adverb (quickly, never)            \n",
        "  'RBR':\"r\", # adverb, comparative (faster)        \n",
        "  'RBS':\"r\", # adverb, superlative (fastest)     \n",
        "  'RP':\"a\", # particle (up, off)\n",
        "  'SYM':\"none\", # symbol (+,%, &)\n",
        "  'TO':\"none\", # “to” (to)\n",
        "  'UH':\"none\", # interjection (ah, oops)\n",
        "  'VB':\"v\", # verb base form (eat)\n",
        "  'VBD':\"v\", # verb past tense (ate)\n",
        "  'VBG':\"v\", # verb gerund (eating)\n",
        "  'VBN':\"v\", # verb past participle (eaten)\n",
        "  'VBP':\"v\", # verb non-3sg pres (eat)\n",
        "  'VBZ':\"v\", # verb 3sg pres (eats)\n",
        "  'WDT':\"none\", # wh-determiner (which, that)\n",
        "  'WP':\"none\", # wh-pronoun (what, who)\n",
        "  'WP$':\"none\", # possessive (wh- whose)\n",
        "  'WRB':\"none\", # wh-adverb (how, where)\n",
        "}\n",
        "\n",
        "# Lemmatizing the words according to the tag_map\n",
        "def lemmatize(p): \n",
        "  wn_tag = tag_map[p[1]]\n",
        "  if wn_tag != \"none\":\n",
        "    return wnl.lemmatize(p[0], pos=wn_tag)\n",
        "  return p[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWLKl9qAP2Un",
        "outputId": "0b5fdca7-3b05-4d30-8a7b-6c783b4957b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.metrics import jaccard_distance\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Lists to save all the lemmatized words\n",
        "text1 = []\n",
        "text2 = []\n",
        "\n",
        "# Adding an empty column to the DataFrame\n",
        "dt['jaccard'] = ''\n",
        "\n",
        "limit = len(dt[0][:])\n",
        "\n",
        "for id in range(limit):\n",
        "\n",
        "  # Tokenization of the 2 texts\n",
        "  tokensText1 = cleaner(nltk.word_tokenize(dt.loc[id,0]))\n",
        "  tokensText2 = cleaner(nltk.word_tokenize(dt.loc[id,1]))\n",
        "\n",
        "  # List of lematized words according to the tags associated\n",
        "  text1.append([lemmatize(pair) for pair in nltk.pos_tag(tokensText1)])\n",
        "  text2.append([lemmatize(pair) for pair in nltk.pos_tag(tokensText2)])\n",
        "\n",
        "  # Updating the DataFrame with the similarities according to the method jaccard \n",
        "  dt.loc[id,'jaccard'] = jaccard_distance(set(text1[id]), set(text2[id]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "S5ESkJrF0fR_",
        "outputId": "2f255607-c5ce-4c29-cd4b-115422767e25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Lists to save all the lemmatized words\\ntext1 = []\\ntext2 = []\\n\\n# Adding an empty column to the DataFrame\\ndt['jaccard_No_Lemmatizer'] = ''\\n\\n# Counter of times where lemmatizer gives worse results\\ncounter = 0\\n\\nlimit = len(dt[0][:])\\n\\nfor id in range(limit):\\n\\n  # Tokenization of the 2 texts\\n  tokensText1 = cleaner(nltk.word_tokenize(dt.loc[id,0]))\\n  tokensText2 = cleaner(nltk.word_tokenize(dt.loc[id,1]))\\n\\n  # List of lematized words according to the tags associated\\n  text1.append(tokensText1)\\n  text2.append(tokensText2)\\n\\n  # Updating the DataFrame with the similarities according to the method jaccard \\n  dt.loc[id,'jaccard_No_Lemmatizer'] = jaccard_distance(set(text1[id]), set(text2[id]))\\n\\n  if (dt.loc[id,'jaccard'] > dt.loc[id,'jaccard_No_Lemmatizer']):\\n    print('id:', id)\\n    print('jaccard with lemmatizer:', float(dt.loc[id,'jaccard']))\\n    print('jaccard without lemmatizer:', float(dt.loc[id,'jaccard_No_Lemmatizer']))\\n    print('gs:', float(dt.loc[id,'gs']))\\n    print('Difference:', abs(float(dt.loc[id,'jaccard']) - float(dt.loc[id,'jaccard_No_Lemmatizer'])))\\n    print('1. Initial phrase:', dt.loc[id,0])\\n    print('1. Tokenized phrase:', text1[id])\\n    print('1. Lemmatized phrase:', nltk.pos_tag(text1[id]))\\n    print('2. Initial phrase:', dt.loc[id,1])\\n    print('2. Tokenized phrase:', text2[id])\\n    print('2. Lemmatized phrase:', nltk.pos_tag(text2[id]), '\\n\\n')\\n    counter = counter + 1\\nprint('The lemmatizer gives worse results', counter, 'times -', int((counter / limit) * 100), '% of the data.')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Additional code to compare gs and jaccard in the same scale\n",
        "'''\n",
        "for id in range(limit):\n",
        "\n",
        "  # Difference between jaccard and gs on the same scale\n",
        "  diff = float(dt.loc[id,'jaccard']) - abs((float(dt.loc[id,'gs']) / 5 - 1))\n",
        "  \n",
        "  # The minDiff variable defines the minimum difference we are looking for\n",
        "  minDiff = 0.8\n",
        "  if (diff > minDiff):\n",
        "    print('id:', id)\n",
        "    print('jaccard:', float(dt.loc[id,'jaccard']))\n",
        "    print('gs:', dt.loc[id,'gs'])\n",
        "    print('Difference in the same scale:', diff)\n",
        "    print('1. Initial phrase:', dt.loc[id,0])\n",
        "    print('1. Tokenized phrase:', text1[id])\n",
        "    print('2. Initial phrase:', dt.loc[id,1])\n",
        "    print('2. Tokenized phrase:', text2[id], '\\n\\n')\n",
        "'''\n",
        "\n",
        "# Additional code to compare jaccard measurement with or without lemmatizer\n",
        "'''\n",
        "# Lists to save all the lemmatized words\n",
        "text1 = []\n",
        "text2 = []\n",
        "\n",
        "# Adding an empty column to the DataFrame\n",
        "dt['jaccard_No_Lemmatizer'] = ''\n",
        "\n",
        "# Counter of times where lemmatizer gives worse results\n",
        "counter = 0\n",
        "\n",
        "limit = len(dt[0][:])\n",
        "\n",
        "for id in range(limit):\n",
        "\n",
        "  # Tokenization of the 2 texts\n",
        "  tokensText1 = cleaner(nltk.word_tokenize(dt.loc[id,0]))\n",
        "  tokensText2 = cleaner(nltk.word_tokenize(dt.loc[id,1]))\n",
        "\n",
        "  # List of lematized words according to the tags associated\n",
        "  text1.append(tokensText1)\n",
        "  text2.append(tokensText2)\n",
        "\n",
        "  # Updating the DataFrame with the similarities according to the method jaccard \n",
        "  dt.loc[id,'jaccard_No_Lemmatizer'] = jaccard_distance(set(text1[id]), set(text2[id]))\n",
        "\n",
        "  if (dt.loc[id,'jaccard'] > dt.loc[id,'jaccard_No_Lemmatizer']):\n",
        "    print('id:', id)\n",
        "    print('jaccard with lemmatizer:', float(dt.loc[id,'jaccard']))\n",
        "    print('jaccard without lemmatizer:', float(dt.loc[id,'jaccard_No_Lemmatizer']))\n",
        "    print('gs:', float(dt.loc[id,'gs']))\n",
        "    print('Difference:', abs(float(dt.loc[id,'jaccard']) - float(dt.loc[id,'jaccard_No_Lemmatizer'])))\n",
        "    print('1. Initial phrase:', dt.loc[id,0])\n",
        "    print('1. Tokenized phrase:', text1[id])\n",
        "    print('1. Lemmatized phrase:', nltk.pos_tag(text1[id]))\n",
        "    print('2. Initial phrase:', dt.loc[id,1])\n",
        "    print('2. Tokenized phrase:', text2[id])\n",
        "    print('2. Lemmatized phrase:', nltk.pos_tag(text2[id]), '\\n\\n')\n",
        "    counter = counter + 1\n",
        "print('The lemmatizer gives worse results', counter, 'times -', int((counter / limit) * 100), '% of the data.')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vNFw27XkWUDW",
        "outputId": "ddeb43d5-75d8-4e30-effe-c607fd2d5e10"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                     0  \\\n",
              "0    The leaders have now been given a new chance a...   \n",
              "1    Amendment No 7 proposes certain changes in the...   \n",
              "2    Let me remind you that our allies include ferv...   \n",
              "3          The vote will take place today at 5.30 p.m.   \n",
              "4    The fishermen are inactive, tired and disappoi...   \n",
              "..                                                 ...   \n",
              "454  It is our job to continue to support Latvia wi...   \n",
              "455        The vote will take place today at 5.30 p.m.   \n",
              "456  Neither was there a qualified majority within ...   \n",
              "457  Let me remind you that our allies include ferv...   \n",
              "458  We often pontificate here about being the repr...   \n",
              "\n",
              "                                                     1     gs   jaccard  \n",
              "0    The leaders benefit aujourd' hui of a new luck...  4.500  0.692308  \n",
              "1    Amendment No 7 is proposing certain changes in...  5.000       0.0  \n",
              "2    I would like to remind you that among our alli...  4.250  0.727273  \n",
              "3                   The vote will take place at 5.30pm  4.500      0.25  \n",
              "4    The fishermen are inactive, tired and disappoi...  5.000       0.0  \n",
              "..                                                 ...    ...       ...  \n",
              "454  It is of our duty of continue to support the c...  5.000  0.636364  \n",
              "455                   Vote will take place at 17 h 30.  4.750  0.571429  \n",
              "456  There was no qualified majority in this Parlia...  5.000  0.636364  \n",
              "457  I hold you recall that our allies, there are e...  4.000       0.8  \n",
              "458  We often take pride here to represent the citi...  3.833     0.625  \n",
              "\n",
              "[459 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-999341bb-8602-46e2-8ac7-8b9cf355aac6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>gs</th>\n",
              "      <th>jaccard</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The leaders have now been given a new chance a...</td>\n",
              "      <td>The leaders benefit aujourd' hui of a new luck...</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amendment No 7 proposes certain changes in the...</td>\n",
              "      <td>Amendment No 7 is proposing certain changes in...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I would like to remind you that among our alli...</td>\n",
              "      <td>4.250</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>The vote will take place at 5.30pm</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>It is our job to continue to support Latvia wi...</td>\n",
              "      <td>It is of our duty of continue to support the c...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>Vote will take place at 17 h 30.</td>\n",
              "      <td>4.750</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Neither was there a qualified majority within ...</td>\n",
              "      <td>There was no qualified majority in this Parlia...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I hold you recall that our allies, there are e...</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>We often pontificate here about being the repr...</td>\n",
              "      <td>We often take pride here to represent the citi...</td>\n",
              "      <td>3.833</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>459 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-999341bb-8602-46e2-8ac7-8b9cf355aac6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-999341bb-8602-46e2-8ac7-8b9cf355aac6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-999341bb-8602-46e2-8ac7-8b9cf355aac6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5shSWosV3bu",
        "outputId": "df06d253-fd69-414e-e7cc-82cb51424296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient: -0.49079034875530486\n",
            "p-value: 3.384400190747036e-29\n"
          ]
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Get the correlation and the p-value between gs and jaccard\n",
        "corr, p = pearsonr(dt['gs'], dt['jaccard'])\n",
        "print(\"Correlation coefficient:\", corr)\n",
        "print(\"p-value:\", p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whfbVZk9MLYT"
      },
      "source": [
        "In this updated version of the code, with the Penn Treebank Tag and the Wordnet's lemmatizer implementation, the correlation coefficient measured by the Pearson method is -0.49, with a p-value of 3.38e-29, a negative non-linear correlation between the gold standard and Jaccard methods. Once again, it's important to note that even though the p-value is diminished, meaning that the null hypothesis is false and there is a correlation between the variables, the amount of data is insufficient to make such a conclusion.\n",
        "\n",
        "Comparing the value obtained with -0.48 (corresponding to the implementation without the lemmatizer), it registered an improvement of 1 percentage point in the correlation, reflecting a low upgrade of the model.\n",
        "\n",
        "The Wordnet's lemmatizer produces this impact, by transforming the words into their basic form (lemmas), according to the characterization (tag) given by the Penn Treebank Tagger. Thus, the similarity method measures phrases, constituted by lemmas instead of words, in which the criteria are more reliable since different words may have the same lemma and, consequentially, equivalent meanings too. Thereby, using lemmas rather than words produces a better approach to the similarity measure.\n",
        "\n",
        "It's essential to point out that as Wordnet's lemmatizer and Penn Treebank Tagger have distinct tags, it was created a dictionary (tag_map) in order to establish the proper correspondences. Particularly, all the types of adjectives provided by the Penn Treebank Tagger were considered as adjectives (the tag 'a' in Wordnet's lemmatizer) since no difference was produced by selecting 'a' or 's'. According to that and a few more tests, it's feasible to conclude that even though Wordnet's lemmatizer differentiates between adjectives (tag 'a') and adjective satellite (tag 's'), it treats the lemmatization of the word identically. \n",
        "\n",
        "To finish, even though the characterization of the words followed by the lemmatizer produces a general improvement (1 percentage point in the correlation), in 5% of the data (24 samples) the similarity decreased. In all of these cases, the gold standard classification is at least 4.50, indicating a very high correlation between sentences. However, in these examples, usually, the order of the words in the second phrase is different, implying a distinguished tag attribution to the same word, leading to non-matching lemmas. As Jaccard compares string in a literal manner, it outputs a better score to identical words than to dissimilar lemmas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}