{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5NDofyd1jg"
      },
      "source": [
        "## Lesk in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR19ZtMQd963",
        "outputId": "71709f25-9254-4085-b8c0-abe49a83ce6b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the file STS.input.SMTeuroparl.txt from drive into a DataFrame\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "dt = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "# Updating the DataFrame with a new column with STS.gs.SMTeuroparl.txt\n",
        "dt['gs'] = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVs-sK0vIuRH",
        "outputId": "53aeaf09-1931-454f-d7f3-82409b3b5585"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Getting a list of stop words\n",
        "nltk.download('stopwords')\n",
        "stopWordSet = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def cleaner (sentenceList):\n",
        "\n",
        "  # Transforming the tag of the words according to the tag_map\n",
        "  sentenceList = [(pair[0], tagger(pair[1])) for pair in sentenceList]\n",
        "  \n",
        "  # Get the list into lowercase\n",
        "  sentenceList = list(map(lambda word: (word[0].lower(), word[1]), sentenceList))\n",
        "\n",
        "  # Filtering the ponctuation and stop words\n",
        "  sentenceList = list(filter(lambda word : re.search('''[!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~]+''', word[0]) == None and word[0] not in stopWordSet, sentenceList))\n",
        "\n",
        "  return sentenceList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw0qmXaNIzzR",
        "outputId": "ff22a479-0839-406d-a6ff-ef89bd274de9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the cleaned sentence without tags\n",
        "def getSentence(cleanedText):\n",
        "  return [pair[0] for pair in cleanedText]"
      ],
      "metadata": {
        "id": "j-PXU4ikQ_ZY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of synsets\n",
        "def synset_lst(sentence, cleanedText, consider_none):\n",
        "  sy_lst = []\n",
        "  for pair in cleanedText:\n",
        "    try:\n",
        "      # Get the synset from a word and appending to the list\n",
        "      sy_lst.append(nltk.wsd.lesk(sentence, pair[0], pair[1]).name())\n",
        "    except:\n",
        "      # Appending the word to the list, when it does not have synset\n",
        "      if (consider_none): sy_lst.append(pair[0])\n",
        "\n",
        "  return sy_lst"
      ],
      "metadata": {
        "id": "TwfJlCj4uf6m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Mapping the tags between Treebank and WordNet\n",
        "tag_map = {\n",
        "  'CC':\"none\", # coordin. conjunction (and, but, or)  \n",
        "  'CD':\"n\", # cardinal number (one, two)             \n",
        "  'DT':\"none\", # determiner (a, the)                    \n",
        "  'EX':\"r\", # existential ‘there’ (there)           \n",
        "  'FW':\"none\", # foreign word (mea culpa)             \n",
        "  'IN':\"r\", # preposition/sub-conj (of, in, by)   \n",
        "  'JJ':\"a\", # adjective (yellow)                  \n",
        "  'JJR':\"a\", # adj., comparative (bigger)          \n",
        "  'JJS':\"a\", # adj., superlative (wildest)           \n",
        "  'LS':\"none\", # list item marker (1, 2, One)          \n",
        "  'MD':\"none\", # modal (can, should)                    \n",
        "  'NN':\"n\", # noun, sing. or mass (llama)          \n",
        "  'NNS':\"n\", # noun, plural (llamas)                  \n",
        "  'NNP':\"n\", # proper noun, sing. (IBM)              \n",
        "  'NNPS':\"n\", # proper noun, plural (Carolinas)\n",
        "  'PDT':\"a\", # predeterminer (all, both)            \n",
        "  'POS':\"none\", # possessive ending (’s )               \n",
        "  'PRP':\"none\", # personal pronoun (I, you, he)     \n",
        "  'PRP$':\"none\", # possessive pronoun (your, one’s)    \n",
        "  'RB':\"r\", # adverb (quickly, never)            \n",
        "  'RBR':\"r\", # adverb, comparative (faster)        \n",
        "  'RBS':\"r\", # adverb, superlative (fastest)     \n",
        "  'RP':\"a\", # particle (up, off)\n",
        "  'SYM':\"none\", # symbol (+,%, &)\n",
        "  'TO':\"none\", # “to” (to)\n",
        "  'UH':\"none\", # interjection (ah, oops)\n",
        "  'VB':\"v\", # verb base form (eat)\n",
        "  'VBD':\"v\", # verb past tense (ate)\n",
        "  'VBG':\"v\", # verb gerund (eating)\n",
        "  'VBN':\"v\", # verb past participle (eaten)\n",
        "  'VBP':\"v\", # verb non-3sg pres (eat)\n",
        "  'VBZ':\"v\", # verb 3sg pres (eats)\n",
        "  'WDT':\"none\", # wh-determiner (which, that)\n",
        "  'WP':\"none\", # wh-pronoun (what, who)\n",
        "  'WP$':\"none\", # possessive (wh- whose)\n",
        "  'WRB':\"none\", # wh-adverb (how, where)\n",
        "}\n",
        "\n",
        "# Transforming the tag of the words according to the tag_map\n",
        "def tagger(tag):\n",
        "  if tag in tag_map.keys():\n",
        "    return tag_map[tag] \n",
        "  return \"none\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RVPz9HCMOAM",
        "outputId": "c9195677-cdd0-413c-d561-32c6c7f61976"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import jaccard_distance\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Adding two empty columns to the DataFrame\n",
        "## Jaccard considering words without tag\n",
        "dt['jaccard_only_synsets'] = ''\n",
        "## Jaccard NOT considering words without tag\n",
        "dt['jaccard_synsets_&_words'] = ''\n",
        "\n",
        "limit = len(dt[0][:])\n",
        "\n",
        "for id in range(limit):\n",
        "\n",
        "  # Tokenization and tagging\n",
        "  tagsText1, tagsText2 = nltk.pos_tag(nltk.word_tokenize(dt.loc[id,0])), nltk.pos_tag(nltk.word_tokenize(dt.loc[id,1]))\n",
        "\n",
        "  # Cleaning \n",
        "  cleanedText1, cleanedText2 = cleaner(tagsText1), cleaner(tagsText2)\n",
        "\n",
        "  # Get the Sentence\n",
        "  sentence1, sentence2 = getSentence(cleanedText1), getSentence(cleanedText2)\n",
        "\n",
        "  # List of cleaned sentences with synsets, considering words without synset\n",
        "  text1_with_none, text2_with_none = synset_lst(sentence1, cleanedText1, True), synset_lst(sentence2, cleanedText2, True)\n",
        "  # List of cleaned sentences with synsets, NOT considering words without synset\n",
        "  text1_no_none, text2_no_none = synset_lst(sentence1, cleanedText1, False), synset_lst(sentence2, cleanedText2, False)\n",
        "  \n",
        "  # Updating the DataFrame with the similarities according to the method jaccard \n",
        "  dt.loc[id,'jaccard_only_synsets'] = jaccard_distance(set(text1_no_none), set(text2_no_none))\n",
        "  dt.loc[id,'jaccard_synsets_&_words'] = jaccard_distance(set(text1_with_none), set(text2_with_none))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRquyFZNI5q_",
        "outputId": "193422be-2028-4abf-82a3-7731d1c2fb61"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dt)"
      ],
      "metadata": {
        "id": "t0dWjzMOJKqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "493e6520-f383-4795-d5d6-86c92cff2aff"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                     0  \\\n",
              "0    The leaders have now been given a new chance a...   \n",
              "1    Amendment No 7 proposes certain changes in the...   \n",
              "2    Let me remind you that our allies include ferv...   \n",
              "3          The vote will take place today at 5.30 p.m.   \n",
              "4    The fishermen are inactive, tired and disappoi...   \n",
              "..                                                 ...   \n",
              "454  It is our job to continue to support Latvia wi...   \n",
              "455        The vote will take place today at 5.30 p.m.   \n",
              "456  Neither was there a qualified majority within ...   \n",
              "457  Let me remind you that our allies include ferv...   \n",
              "458  We often pontificate here about being the repr...   \n",
              "\n",
              "                                                     1     gs  \\\n",
              "0    The leaders benefit aujourd' hui of a new luck...  4.500   \n",
              "1    Amendment No 7 is proposing certain changes in...  5.000   \n",
              "2    I would like to remind you that among our alli...  4.250   \n",
              "3                   The vote will take place at 5.30pm  4.500   \n",
              "4    The fishermen are inactive, tired and disappoi...  5.000   \n",
              "..                                                 ...    ...   \n",
              "454  It is of our duty of continue to support the c...  5.000   \n",
              "455                   Vote will take place at 17 h 30.  4.750   \n",
              "456  There was no qualified majority in this Parlia...  5.000   \n",
              "457  I hold you recall that our allies, there are e...  4.000   \n",
              "458  We often take pride here to represent the citi...  3.833   \n",
              "\n",
              "    jaccard_only_synsets jaccard_synsets_&_words  \n",
              "0                    0.6                0.692308  \n",
              "1                    0.0                     0.0  \n",
              "2                  0.625                0.727273  \n",
              "3                   0.25                    0.25  \n",
              "4                    0.0                     0.0  \n",
              "..                   ...                     ...  \n",
              "454             0.727273                    0.75  \n",
              "455             0.571429                0.571429  \n",
              "456             0.666667                0.636364  \n",
              "457             0.777778                     0.8  \n",
              "458                0.625                   0.625  \n",
              "\n",
              "[459 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92cb0c8a-52c1-4c4f-853c-4d6122ea0c2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>gs</th>\n",
              "      <th>jaccard_only_synsets</th>\n",
              "      <th>jaccard_synsets_&amp;_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The leaders have now been given a new chance a...</td>\n",
              "      <td>The leaders benefit aujourd' hui of a new luck...</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amendment No 7 proposes certain changes in the...</td>\n",
              "      <td>Amendment No 7 is proposing certain changes in...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I would like to remind you that among our alli...</td>\n",
              "      <td>4.250</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>The vote will take place at 5.30pm</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>It is our job to continue to support Latvia wi...</td>\n",
              "      <td>It is of our duty of continue to support the c...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>Vote will take place at 17 h 30.</td>\n",
              "      <td>4.750</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Neither was there a qualified majority within ...</td>\n",
              "      <td>There was no qualified majority in this Parlia...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I hold you recall that our allies, there are e...</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>We often pontificate here about being the repr...</td>\n",
              "      <td>We often take pride here to represent the citi...</td>\n",
              "      <td>3.833</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>459 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92cb0c8a-52c1-4c4f-853c-4d6122ea0c2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92cb0c8a-52c1-4c4f-853c-4d6122ea0c2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92cb0c8a-52c1-4c4f-853c-4d6122ea0c2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Get the correlation and the p-value between gs and jaccard\n",
        "corr, p = pearsonr(dt['gs'], dt['jaccard_only_synsets'])\n",
        "print(\"Only synsets -> Correlation coefficient:\", corr)\n",
        "print(\"Only synsets -> p-value:\", p)\n",
        "print('\\n')\n",
        "\n",
        "corr, p = pearsonr(dt['gs'], dt['jaccard_synsets_&_words'])\n",
        "print(\"Synsets + words without synset -> Correlation coefficient:\", corr)\n",
        "print(\"Synsets + words without synset -> p-value:\", p)"
      ],
      "metadata": {
        "id": "n9GtDC-ZB6oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e16c5d-9f48-482d-f8ea-ae2db3950de3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only synsets -> Correlation coefficient: -0.5139698634879429\n",
            "Only synsets -> p-value: 2.615398269826006e-32\n",
            "\n",
            "\n",
            "Synsets + words without synset -> Correlation coefficient: -0.5086380711515205\n",
            "Synsets + words without synset -> p-value: 1.4275649732895514e-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**"
      ],
      "metadata": {
        "id": "C4Sq6osDBD7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this updated version of the code, the application of Lesk’s algorithm to get the synsets from words was performed two approaches, in order to obtain the Jaccard Similarity and the Pearson Correlation.\n",
        "\n",
        "In the first case, only the words with synsets are considered, while in the second example, besides the words with synsets, the others are also considered to be the similarity measure, as they are in their natural form. \n",
        "\n",
        "The results from the experiment show that comparing only synsets provide a  Correlation coefficient to the gold standard of -0.514 and a P-value of p-value: 2.6e-32.  \n",
        "When the words without synsets were included in the comparison, the correlation decreased to -0.509, with a p-value of 1.4e-31.\n",
        "In both methods, it is visible a negative non-linear correlation between the gold standard and Jaccard methods and, even though the p-value is diminished, meaning that the null hypothesis is false and there is a correlation between the variables, the amount of data is insufficient to make such a conclusion.\n",
        "\n",
        "Firstly, the results obtained are better than the previous implementations in Lab 2 Document with -0.48 (just the cleaning of the text), and Lab 3 Morphology with -0.491 (cleaning of the text + Lemmatizer).\n",
        "\n",
        "In Lab 3 was stated the following about the lemmatizer comparing Lab2 and Lab3:\n",
        "\n",
        "\" The Wordnet's lemmatizer produces this improvement, by transforming the words into their basic form (lemmas), according to the characterization (tag) given by the Penn Treebank Tagger. Thus, the similarity method measures phrases, constituted by lemmas instead of words, in which the criteria are more reliable since different words may have the same lemma and, consequentially, equivalent meanings too. Thereby, using lemmas rather than words produces a better approach to the similarity measure.\"\n",
        "\n",
        "So, when Lesk’s algorithm is applied, we are able to obtain the following configuration:\n",
        "\n",
        "\"\n",
        "\n",
        "lemma.pos.number\n",
        "\n",
        "-> lemma is the word's morphological stem\n",
        "\n",
        "-> pos is one of the modules attributes ADJ, ADJ_SAT, ADV, NOUN or VERB\n",
        "\n",
        "-> number is the sense number, counting from 0.\n",
        "\n",
        "\" (NLTK Documentation)\n",
        "\n",
        "Which, returns not only the lemmas but also the tag related to the word and the sense number. This way, the description we obtain is more reliable since we consider the meaning of a word, with a more detailed description than just the lemma (as in Lab 3).\n",
        "\n",
        "As a last topic, considering the values obtained only in this practical exercise, it is visible that the Correlation coefficient is more satisfactory when only synsets are considered. In fact, this indicates that, when words are compared in their natural form, very little information is deemed, introducing some errors in the Jaccard measurement. However, the removal of non-synset words gives only an improvement of 0.005 percentage points, which is in the range of uncertainty. Nonetheless, with the increment of words without synsets, the error introduced is bigger, decreasing the correlation value. Thus, for this application it is more benefic do not to consider words without synsets.\n",
        "\n",
        "As a final note, it is important to denote that, even though it was registered an improvement, the correlation obtained stills not being sufficiently satisfying, mainly due to the method used to compare strings."
      ],
      "metadata": {
        "id": "5WjCd9hJGRZL"
      }
    }
  ]
}