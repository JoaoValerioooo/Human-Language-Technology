{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzdQPYNKA25p",
        "outputId": "593d9af3-500b-4718-ba86-f5041688cd49"
      },
      "source": [
        "import nltk\n",
        "from tabulate import tabulate\n",
        "from nltk.corpus import wordnet_ic\n",
        "import numpy as np\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "nltk.download('omw-1.4')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3p7rB7ZAcPq"
      },
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_pairs = (('the','DT'), ('man','NN'), ('swim','VB'), ('with', 'PR'), ('a', 'DT'),\n",
        "('girl','NN'), ('and', 'CC'), ('a', 'DT'), ('boy', 'NN'), ('whilst', 'PR'),\n",
        "('the', 'DT'), ('woman', 'NN'), ('walk', 'VB'))"
      ],
      "metadata": {
        "id": "RWnfesc2uvRc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mapping the tags between Treebank and WordNet\n",
        "tag_map = {\n",
        "  'CC':\"none\", # coordin. conjunction (and, but, or)  \n",
        "  'CD':\"n\", # cardinal number (one, two)             \n",
        "  'DT':\"none\", # determiner (a, the)                    \n",
        "  'EX':\"r\", # existential ‘there' (there)           \n",
        "  'FW':\"none\", # foreign word (mea culpa)             \n",
        "  'IN':\"r\", # preposition/sub-conj (of, in, by)   \n",
        "  'JJ':\"a\", # adjective (yellow)                  \n",
        "  'JJR':\"a\", # adj., comparative (bigger)          \n",
        "  'JJS':\"a\", # adj., superlative (wildest)           \n",
        "  'LS':\"none\", # list item marker (1, 2, One)          \n",
        "  'MD':\"none\", # modal (can, should)                    \n",
        "  'NN':\"n\", # noun, sing. or mass (llama)          \n",
        "  'NNS':\"n\", # noun, plural (llamas)                  \n",
        "  'NNP':\"n\", # proper noun, sing. (IBM)              \n",
        "  'NNPS':\"n\", # proper noun, plural (Carolinas)\n",
        "  'PDT':\"a\", # predeterminer (all, both)            \n",
        "  'POS':\"none\", # possessive ending ('s )               \n",
        "  'PRP':\"none\", # personal pronoun (I, you, he)     \n",
        "  'PRP$':\"none\", # possessive pronoun (your, one's)    \n",
        "  'RB':\"r\", # adverb (quickly, never)            \n",
        "  'RBR':\"r\", # adverb, comparative (faster)        \n",
        "  'RBS':\"r\", # adverb, superlative (fastest)     \n",
        "  'RP':\"a\", # particle (up, off)\n",
        "  'SYM':\"none\", # symbol (+,%, &)\n",
        "  'TO':\"none\", # “to” (to)\n",
        "  'UH':\"none\", # interjection (ah, oops)\n",
        "  'VB':\"v\", # verb base form (eat)\n",
        "  'VBD':\"v\", # verb past tense (ate)\n",
        "  'VBG':\"v\", # verb gerund (eating)\n",
        "  'VBN':\"v\", # verb past participle (eaten)\n",
        "  'VBP':\"v\", # verb non-3sg pres (eat)\n",
        "  'VBZ':\"v\", # verb 3sg pres (eats)\n",
        "  'WDT':\"none\", # wh-determiner (which, that)\n",
        "  'WP':\"none\", # wh-pronoun (what, who)\n",
        "  'WP$':\"none\", # possessive (wh- whose)\n",
        "  'WRB':\"none\", # wh-adverb (how, where)\n",
        "}\n",
        "\n",
        "def tb_to_wn(tag): \n",
        "  if(tag in tag_map):\n",
        "    return tag_map[tag]\n",
        "  else:\n",
        "    return \"none\"\n",
        "  return tag"
      ],
      "metadata": {
        "id": "DBaVPUKWJmyh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT83t-mgArER",
        "outputId": "8e88233e-65a3-4f1e-f679-73e6a874b692"
      },
      "source": [
        "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "\n",
        "#Retrieving the synsets from the word pairs\n",
        "words = [pair[0] for pair in word_pairs if tb_to_wn(pair[1]) != \"none\"]\n",
        "synsets = [wn.synsets(pair[0],tb_to_wn(pair[1]))[0] for pair in word_pairs if tb_to_wn(pair[1]) != \"none\"]\n",
        "similarity_matrix = [[None for i in range(len(words) + 1)] for j in range(len(words) + 1)]\n",
        "LCS_matrix = np.copy(similarity_matrix)\n",
        "\n",
        "#Print the most common synonyms\n",
        "print(\"Most common synsets:\")\n",
        "for word,syn in zip(words,synsets):\n",
        "  print(word,\":\",str(syn)[8:-2])\n",
        "\n",
        "#Defining the tables\n",
        "similarity_matrix[0][0] = \"Similarity matrix\"\n",
        "LCS_matrix[0][0] = \"Least common subsumer\"\n",
        "\n",
        "#Creating headers to the tables\n",
        "for first_synset,i in zip(synsets,range(len(word_pairs))):\n",
        "  similarity_matrix[0][i+1] = str(synsets[i])[8:-2]\n",
        "  similarity_matrix[i+1][0] = str(synsets[i])[8:-2]\n",
        "  LCS_matrix[i+1][0]= str(synsets[i])[8:-2]\n",
        "  LCS_matrix[0][i+1]= str(synsets[i])[8:-2]\n",
        "#Compute the similarities\n",
        "  for second_synset,j in zip(synsets,range(len(word_pairs))):\n",
        "    similarities = \"{:0.2f}  | \".format(first_synset.path_similarity(second_synset))\n",
        "\n",
        "    if(str(first_synset)[-6] == str(second_synset)[-6]): #If the POS tags of the synsets are idetical\n",
        "      similarities += \"{:0.2f}  | \".format((first_synset.lch_similarity(second_synset)-0.7472144018302211)/(first_synset.lch_similarity(first_synset)-0.7472144018302211)) #normalizing between 1 and 0\n",
        "      similarities += \"{:0.2f}  | \".format(first_synset.lin_similarity(second_synset,brown_ic),2)\n",
        "      LCS_matrix[i+1][j+1] = str(first_synset.lowest_common_hypernyms(second_synset)[0])[8:-2]\n",
        "    else:\n",
        "      similarities += \"----- | ----- | \"\n",
        "      LCS_matrix[i+1][j+1] = \"-----\"\n",
        "    similarities += \"{:0.2f}\".format(first_synset.wup_similarity(second_synset),2)\n",
        "\n",
        "    similarity_matrix[i+1][j+1] = similarities\n",
        "    \n",
        "print(\"\\n\")\n",
        "print(tabulate(similarity_matrix, headers='firstrow', tablefmt='fancy_grid'))\n",
        "print(\"The values in each cell coresponds to: Path Similarity | Leacock-Chodorow Similarity | Lin Similarity | Wu-Palmer Similarity\")\n",
        "print(\"\\n\")\n",
        "print(tabulate(LCS_matrix, headers='firstrow', tablefmt='fancy_grid'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common synsets:\n",
            "man : man.n.01\n",
            "swim : swim.v.01\n",
            "girl : girl.n.01\n",
            "boy : male_child.n.01\n",
            "woman : woman.n.01\n",
            "walk : walk.v.01\n",
            "\n",
            "\n",
            "╒═════════════════════╤══════════════════════════════╤══════════════════════════════╤══════════════════════════════╤══════════════════════════════╤══════════════════════════════╤══════════════════════════════╕\n",
            "│ Similarity matrix   │ man.n.01                     │ swim.v.01                    │ girl.n.01                    │ male_child.n.01              │ woman.n.01                   │ walk.v.01                    │\n",
            "╞═════════════════════╪══════════════════════════════╪══════════════════════════════╪══════════════════════════════╪══════════════════════════════╪══════════════════════════════╪══════════════════════════════╡\n",
            "│ man.n.01            │ 1.00  | 1.00  | 1.00  | 1.00 │ 0.10  | ----- | ----- | 0.18 │ 0.25  | 0.52  | 0.71  | 0.63 │ 0.33  | 0.62  | 0.73  | 0.67 │ 0.33  | 0.62  | 0.79  | 0.67 │ 0.10  | ----- | ----- | 0.18 │\n",
            "├─────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤\n",
            "│ swim.v.01           │ 0.10  | ----- | ----- | 0.18 │ 1.00  | 1.00  | 1.00  | 1.00 │ 0.09  | ----- | ----- | 0.17 │ 0.10  | ----- | ----- | 0.18 │ 0.10  | ----- | ----- | 0.18 │ 0.33  | 0.56  | 0.49  | 0.33 │\n",
            "├─────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤\n",
            "│ girl.n.01           │ 0.25  | 0.52  | 0.71  | 0.63 │ 0.09  | ----- | ----- | 0.17 │ 1.00  | 1.00  | 1.00  | 1.00 │ 0.17  | 0.38  | 0.29  | 0.63 │ 0.50  | 0.76  | 0.91  | 0.63 │ 0.09  | ----- | ----- | 0.17 │\n",
            "├─────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤\n",
            "│ male_child.n.01     │ 0.33  | 0.62  | 0.73  | 0.67 │ 0.10  | ----- | ----- | 0.18 │ 0.17  | 0.38  | 0.29  | 0.63 │ 1.00  | 1.00  | 1.00  | 1.00 │ 0.20  | 0.44  | 0.32  | 0.67 │ 0.10  | ----- | ----- | 0.18 │\n",
            "├─────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤\n",
            "│ woman.n.01          │ 0.33  | 0.62  | 0.79  | 0.67 │ 0.10  | ----- | ----- | 0.18 │ 0.50  | 0.76  | 0.91  | 0.95 │ 0.20  | 0.44  | 0.32  | 0.67 │ 1.00  | 1.00  | 1.00  | 1.00 │ 0.10  | ----- | ----- | 0.18 │\n",
            "├─────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤\n",
            "│ walk.v.01           │ 0.10  | ----- | ----- | 0.18 │ 0.33  | 0.56  | 0.49  | 0.33 │ 0.09  | ----- | ----- | 0.17 │ 0.10  | ----- | ----- | 0.18 │ 0.10  | ----- | ----- | 0.18 │ 1.00  | 1.00  | 1.00  | 1.00 │\n",
            "╘═════════════════════╧══════════════════════════════╧══════════════════════════════╧══════════════════════════════╧══════════════════════════════╧══════════════════════════════╧══════════════════════════════╛\n",
            "The values in each cell coresponds to: Path Similarity | Leacock-Chodorow Similarity | Lin Similarity | Wu-Palmer Similarity\n",
            "\n",
            "\n",
            "╒═════════════════════════╤════════════╤═════════════╤═════════════╤═══════════════════╤══════════════╤═════════════╕\n",
            "│ Least common subsumer   │ man.n.01   │ swim.v.01   │ girl.n.01   │ male_child.n.01   │ woman.n.01   │ walk.v.01   │\n",
            "╞═════════════════════════╪════════════╪═════════════╪═════════════╪═══════════════════╪══════════════╪═════════════╡\n",
            "│ man.n.01                │ man.n.01   │ -----       │ adult.n.01  │ male.n.02         │ adult.n.01   │ -----       │\n",
            "├─────────────────────────┼────────────┼─────────────┼─────────────┼───────────────────┼──────────────┼─────────────┤\n",
            "│ swim.v.01               │ -----      │ swim.v.01   │ -----       │ -----             │ -----        │ travel.v.01 │\n",
            "├─────────────────────────┼────────────┼─────────────┼─────────────┼───────────────────┼──────────────┼─────────────┤\n",
            "│ girl.n.01               │ adult.n.01 │ -----       │ girl.n.01   │ person.n.01       │ woman.n.01   │ -----       │\n",
            "├─────────────────────────┼────────────┼─────────────┼─────────────┼───────────────────┼──────────────┼─────────────┤\n",
            "│ male_child.n.01         │ male.n.02  │ -----       │ person.n.01 │ male_child.n.01   │ person.n.01  │ -----       │\n",
            "├─────────────────────────┼────────────┼─────────────┼─────────────┼───────────────────┼──────────────┼─────────────┤\n",
            "│ woman.n.01              │ adult.n.01 │ -----       │ woman.n.01  │ person.n.01       │ woman.n.01   │ -----       │\n",
            "├─────────────────────────┼────────────┼─────────────┼─────────────┼───────────────────┼──────────────┼─────────────┤\n",
            "│ walk.v.01               │ -----      │ travel.v.01 │ -----       │ -----             │ -----        │ walk.v.01   │\n",
            "╘═════════════════════════╧════════════╧═════════════╧═════════════╧═══════════════════╧══════════════╧═════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   The similarity between a synset to itself is 1 as expected, since the path disctance is 0, while a synset with far distances has a similarity value close to 0, like nouns and verbs.\n",
        "2.   Between the methods, the variation of the similarities can be pretty significant. For instance between the synsets man.n.01 and girl.n.01 or woman.n.01, the biggest difference in similarity is observed, with a value of 0.46. This states that it's not possible to compare the results from different methods, since use very different formulas.\n",
        "3.   The similarities are usually symmetric, but for wu-palmer similarity, the values are 0.63 for a woman-girl, while it is 0.95 for girl - woman. This is unexpected since the LCS and the respective depths are equal. Furthermore, this is not observed in other word pairs.\n",
        "4.   The synsets in the table represent meanings and not only the lemmas. Different meanings are distinguished by the number. For instance, wordnet gives the example of girl.n.01 as 'a young lady of 18', while girl.n.02 is explained as 'the baby was a girl'.\n",
        "\n",
        "Conclusion\n",
        "According to the results from the provided word set, the preferable method is ln similarity. Firstly, it is the method with the most consistent output, according to the human perception of synonyms. For instance, Woman and girl should have more similarities than woman and male child.\n",
        "Furthermore, the equation considers more parameters, like the information content from the frequencies in a corpus, leading to more precise and reliable values.\n",
        "\n",
        "To finish, it's important to mention that the sample size is not big enough to reach a solid conclusion about the best method, and also that these representations of synonyms and formulas lack on flexibility to efficiently represent the common human language."
      ],
      "metadata": {
        "id": "k7_FMJHV2Ifd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Examples of meanings of synsets\n",
        "# print(wn.synset(\"girl.n.01\").examples())\n",
        "# print(wn.synset(\"girl.n.02\").examples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiucJArF9gjj",
        "outputId": "cc5ba773-e690-4628-95e8-f4fe793b55a1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a young lady of 18']\n",
            "['the baby was a girl', 'the girls were just learning to ride a tricycle']\n"
          ]
        }
      ]
    }
  ]
}