{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti5NDofyd1jg"
      },
      "source": [
        "## NERC in NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR19ZtMQd963",
        "outputId": "8773523c-6316-4664-9e67-a820803203a2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the file STS.input.SMTeuroparl.txt from drive into a DataFrame\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "dt = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None)\n",
        "# Updating the DataFrame with a new column with STS.gs.SMTeuroparl.txt\n",
        "dt['gs'] = pd.read_csv('/content/drive/MyDrive/data/ihlt/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVs-sK0vIuRH",
        "outputId": "2068bb93-316d-451a-bb94-356f7b3de127"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Getting a list of stop words\n",
        "nltk.download('stopwords')\n",
        "stopWordSet = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Cleaning the words\n",
        "def cleaner (sentenceList):\n",
        "  \n",
        "  # Transforming the tag of the words according to the tag_map\n",
        "  sentenceList = [(pair[0], tagger(pair[1]), pair[2]) for pair in sentenceList]\n",
        "\n",
        "  # Get the list into lowercase\n",
        "  sentenceList = list(map(lambda word: (word[0].lower(), word[1], word[2]), sentenceList))\n",
        "\n",
        "  # Filtering the ponctuation and stop words\n",
        "  sentenceList = list(filter(lambda word : re.search('''[!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~]+''', word[0]) == None and word[0] not in stopWordSet, sentenceList))\n",
        "\n",
        "  return sentenceList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw0qmXaNIzzR",
        "outputId": "8ad7b22a-78c5-417a-b96b-a6a8d1156586"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "# Mapping the tags between Treebank and WordNet\n",
        "tag_map = {\n",
        "  'CC':\"none\", # coordin. conjunction (and, but, or)  \n",
        "  'CD':\"n\", # cardinal number (one, two)             \n",
        "  'DT':\"none\", # determiner (a, the)                    \n",
        "  'EX':\"r\", # existential ‘there’ (there)           \n",
        "  'FW':\"none\", # foreign word (mea culpa)             \n",
        "  'IN':\"r\", # preposition/sub-conj (of, in, by)   \n",
        "  'JJ':\"a\", # adjective (yellow)                  \n",
        "  'JJR':\"a\", # adj., comparative (bigger)          \n",
        "  'JJS':\"a\", # adj., superlative (wildest)           \n",
        "  'LS':\"none\", # list item marker (1, 2, One)          \n",
        "  'MD':\"none\", # modal (can, should)                    \n",
        "  'NN':\"n\", # noun, sing. or mass (llama)          \n",
        "  'NNS':\"n\", # noun, plural (llamas)                  \n",
        "  'NNP':\"n\", # proper noun, sing. (IBM)              \n",
        "  'NNPS':\"n\", # proper noun, plural (Carolinas)\n",
        "  'PDT':\"a\", # predeterminer (all, both)            \n",
        "  'POS':\"none\", # possessive ending (’s )               \n",
        "  'PRP':\"none\", # personal pronoun (I, you, he)     \n",
        "  'PRP$':\"none\", # possessive pronoun (your, one’s)    \n",
        "  'RB':\"r\", # adverb (quickly, never)            \n",
        "  'RBR':\"r\", # adverb, comparative (faster)        \n",
        "  'RBS':\"r\", # adverb, superlative (fastest)     \n",
        "  'RP':\"a\", # particle (up, off)\n",
        "  'SYM':\"none\", # symbol (+,%, &)\n",
        "  'TO':\"none\", # “to” (to)\n",
        "  'UH':\"none\", # interjection (ah, oops)\n",
        "  'VB':\"v\", # verb base form (eat)\n",
        "  'VBD':\"v\", # verb past tense (ate)\n",
        "  'VBG':\"v\", # verb gerund (eating)\n",
        "  'VBN':\"v\", # verb past participle (eaten)\n",
        "  'VBP':\"v\", # verb non-3sg pres (eat)\n",
        "  'VBZ':\"v\", # verb 3sg pres (eats)\n",
        "  'WDT':\"none\", # wh-determiner (which, that)\n",
        "  'WP':\"none\", # wh-pronoun (what, who)\n",
        "  'WP$':\"none\", # possessive (wh- whose)\n",
        "  'WRB':\"none\", # wh-adverb (how, where)\n",
        "}\n",
        "\n",
        "# Transforming the tag of the words according to the tag_map\n",
        "def tagger(tag):\n",
        "  if tag in tag_map.keys():\n",
        "    return tag_map[tag] \n",
        "  return \"none\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8k2BLgZ7c-q",
        "outputId": "0301474c-4c12-4780-f4f6-425ac75df86c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NE_joiner (cleanedText):\n",
        "  Text = []\n",
        "  for pair in cleanedText:\n",
        "    if pair[2] == 'O' or 'B-' in pair[2]: Text.append(pair[0])\n",
        "    elif('I-' in pair[2]): Text[-1] = ' '.join((Text[-1], pair[0]))\n",
        "  return Text"
      ],
      "metadata": {
        "id": "PhKuiWzk90_b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics import jaccard_distance\n",
        "import numpy as np\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Adding 3 empty columns to the DataFrame\n",
        "# Just words\n",
        "dt['jaccard_Word'] = ''\n",
        "# words + PERSON, LOCATION, ORGZATION NEs classifcations merged\n",
        "dt['jaccard_Word_NEs'] = ''\n",
        "\n",
        "limit = len(dt[0][:])\n",
        "\n",
        "for id in range(limit):\n",
        "\n",
        "  # Tokenization and tagging\n",
        "  tagsText1, tagsText2 = nltk.pos_tag(nltk.word_tokenize(dt.loc[id,0])), nltk.pos_tag(nltk.word_tokenize(dt.loc[id,1]))\n",
        "\n",
        "  # Chunck\n",
        "  chunckText1, chunckText2 = nltk.tree2conlltags(nltk.ne_chunk(tagsText1)), nltk.tree2conlltags(nltk.ne_chunk(tagsText2))\n",
        "\n",
        "  # Cleaning \n",
        "  cleanedText1, cleanedText2 = cleaner(chunckText1), cleaner(chunckText2)\n",
        "\n",
        "  # List of words\n",
        "  Text1, Text2 = [pair[0] for pair in cleanedText1], [pair[0] for pair in cleanedText2]\n",
        "  \n",
        "  # List of words  + Merging correspondent NEs\n",
        "  Text1_NEs, Text2_NEs = NE_joiner(cleanedText1), NE_joiner(cleanedText2)\n",
        "\n",
        "  # Updating the DataFrame with the similarities according to the method jaccard\n",
        "  dt.loc[id,'jaccard_Word'] = jaccard_distance(set(Text1), set(Text2))\n",
        "  dt.loc[id,'jaccard_Word_NEs'] = jaccard_distance(set(Text1_NEs), set(Text2_NEs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRquyFZNI5q_",
        "outputId": "289c8e54-bb59-43ad-cef3-16f31ad96174"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(dt)"
      ],
      "metadata": {
        "id": "t0dWjzMOJKqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "5ee7903e-2feb-4916-ca58-d6580aa8f180"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                     0  \\\n",
              "0    The leaders have now been given a new chance a...   \n",
              "1    Amendment No 7 proposes certain changes in the...   \n",
              "2    Let me remind you that our allies include ferv...   \n",
              "3          The vote will take place today at 5.30 p.m.   \n",
              "4    The fishermen are inactive, tired and disappoi...   \n",
              "..                                                 ...   \n",
              "454  It is our job to continue to support Latvia wi...   \n",
              "455        The vote will take place today at 5.30 p.m.   \n",
              "456  Neither was there a qualified majority within ...   \n",
              "457  Let me remind you that our allies include ferv...   \n",
              "458  We often pontificate here about being the repr...   \n",
              "\n",
              "                                                     1     gs jaccard_Word  \\\n",
              "0    The leaders benefit aujourd' hui of a new luck...  4.500     0.692308   \n",
              "1    Amendment No 7 is proposing certain changes in...  5.000         0.25   \n",
              "2    I would like to remind you that among our alli...  4.250     0.727273   \n",
              "3                   The vote will take place at 5.30pm  4.500         0.25   \n",
              "4    The fishermen are inactive, tired and disappoi...  5.000          0.0   \n",
              "..                                                 ...    ...          ...   \n",
              "454  It is of our duty of continue to support the c...  5.000     0.636364   \n",
              "455                   Vote will take place at 17 h 30.  4.750     0.571429   \n",
              "456  There was no qualified majority in this Parlia...  5.000     0.636364   \n",
              "457  I hold you recall that our allies, there are e...  4.000          0.8   \n",
              "458  We often take pride here to represent the citi...  3.833        0.625   \n",
              "\n",
              "    jaccard_Word_NEs  \n",
              "0           0.692308  \n",
              "1               0.25  \n",
              "2           0.727273  \n",
              "3               0.25  \n",
              "4                0.0  \n",
              "..               ...  \n",
              "454         0.636364  \n",
              "455         0.571429  \n",
              "456         0.636364  \n",
              "457              0.8  \n",
              "458            0.625  \n",
              "\n",
              "[459 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc260952-3189-44b7-8e5b-49247d8326d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>gs</th>\n",
              "      <th>jaccard_Word</th>\n",
              "      <th>jaccard_Word_NEs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The leaders have now been given a new chance a...</td>\n",
              "      <td>The leaders benefit aujourd' hui of a new luck...</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.692308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Amendment No 7 proposes certain changes in the...</td>\n",
              "      <td>Amendment No 7 is proposing certain changes in...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I would like to remind you that among our alli...</td>\n",
              "      <td>4.250</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>The vote will take place at 5.30pm</td>\n",
              "      <td>4.500</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>The fishermen are inactive, tired and disappoi...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>It is our job to continue to support Latvia wi...</td>\n",
              "      <td>It is of our duty of continue to support the c...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>The vote will take place today at 5.30 p.m.</td>\n",
              "      <td>Vote will take place at 17 h 30.</td>\n",
              "      <td>4.750</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Neither was there a qualified majority within ...</td>\n",
              "      <td>There was no qualified majority in this Parlia...</td>\n",
              "      <td>5.000</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.636364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>Let me remind you that our allies include ferv...</td>\n",
              "      <td>I hold you recall that our allies, there are e...</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>We often pontificate here about being the repr...</td>\n",
              "      <td>We often take pride here to represent the citi...</td>\n",
              "      <td>3.833</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>459 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc260952-3189-44b7-8e5b-49247d8326d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc260952-3189-44b7-8e5b-49247d8326d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc260952-3189-44b7-8e5b-49247d8326d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Get the correlation and the p-value between gs and jaccard\n",
        "corr, p = pearsonr(dt['gs'], dt['jaccard_Word'])\n",
        "print(\"Only Words -> Correlation coefficient:\", corr)\n",
        "print(\"Only Words -> p-value:\", p)\n",
        "\n",
        "corr, p = pearsonr(dt['gs'], dt['jaccard_Word_NEs'])\n",
        "print(\"\\nWords + NEs -> Correlation coefficient:\", corr)\n",
        "print(\"Words + NEs -> p-value:\", p)"
      ],
      "metadata": {
        "id": "n9GtDC-ZB6oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf5454e-5d01-4585-dd34-f9a526af578a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only Words -> Correlation coefficient: -0.48094173868814033\n",
            "Only Words -> p-value: 6.04463003283716e-28\n",
            "\n",
            "Words + NEs -> Correlation coefficient: -0.460948400467054\n",
            "Words + NEs -> p-value: 1.589479127847856e-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**"
      ],
      "metadata": {
        "id": "C4Sq6osDBD7e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This updated version of the code applies the Maximum entropy model from NLTK (PERSON, LOCATION, ORGANIZATION) trained with ACE corpus to obtain the Jaccard Similarity and the Pearson Correlation.\n",
        "\n",
        "Firstly, it is chosen to represent the words in their basic form, in order to comprehend in isolation the effect of considering NEs.\n",
        "\n",
        "In this analysis 2 approaches were considered:\n",
        "\n",
        "*   **1 - Only Words:**\n",
        "\n",
        "    Correlation coefficient: -0.481\n",
        "\n",
        "    p-value: 6.044e-28\n",
        "\n",
        "*   **2 - Words considering the PERSON, LOCATION, ORGANIZATION NEs classifications:**\n",
        "\n",
        "    Correlation coefficient: -0.461\n",
        "\n",
        "    p-value: 1.589e-25\n",
        "\n",
        "\n",
        "In both methods, it is visible a negative non-linear correlation between the gold standard and Jaccard methods and, even though the p-value is diminished, meaning that the null hypothesis is false and there is a correlation between the variables, the amount of data is insufficient to make such a conclusion.\n",
        "\n",
        "Furthermore, by comparing both correlations it is understandable that, for this data set, if only words are considered the correlation between the Jaccard similarity and the Pearson correlation is higher.\n",
        "\n",
        "Particularly, it is not registered a single improvement in the similarity between the phrases when the NEs are considered. This is due to the fact that, by considering an NE and merging subsequent words with the same label associated, the number of instances to compare is reduced.\n",
        "For example, in the following texts, the Jaccard similarity perceives that 2 strings are the same (2/3):\n",
        "\n",
        "Text1 = ['The', 'european', 'union']\n",
        "Text2 = ['A', 'european', 'union']\n",
        "\n",
        "However, when considering NEs, the texts would be:\n",
        "\n",
        "Text1 = ['The', 'european union']\n",
        "Text2 = ['A', 'european union']\n",
        "\n",
        "In which, for the same phrases, only one string is actually similar (1/2). Consequentially, the overall similarity decreases.\n",
        "\n",
        "Additionally, the previous analysis is not enough to point out that this approach is not beneficial in a text comparison. Firstly, as 95.4% of the words do not belong to the first 3 categories referred, in almost all the cases the words are assigned with 'O'.\n",
        "Then, the dataset is not big enough or with a considerable amount of variety in the examples.\n",
        "Additionally, the method is sensitive to the order of the words and lower/upper case configurations that can be prejudicial occasionally.\n",
        "Finally, when 2 phrases should hold very high similarity, using NEs might result in a decrement in the similarity and the correlation, since fewer instances with a unitary Jaccard classification are being considered. Nonetheless, when 2 phrases should have extremely low similarity, decreasing the instances by considering NEs might lead to better correlation results.\n",
        "\n",
        "To conclude, using NEs might be helpful depending on the number of classifications provided and the dataset considered. Furthermore, it is necessary to denote that the correlation obtained is not sufficiently satisfying."
      ],
      "metadata": {
        "id": "5WjCd9hJGRZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLTK RegexpParser"
      ],
      "metadata": {
        "id": "M2LGpX0tJdm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install svgling\n",
        "import svgling\n",
        "# Sentence considered\n",
        "sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"),(\"dog\", \"NN\"),\\\n",
        "            (\"barked\", \"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\"), \\\n",
        "            (\"in\", \"IN\"), (\"New\", \"NNP\"), (\"York\", \"NNP\")]\n",
        "\n",
        "# Grammar definition\n",
        "grammar = \"\"\"NP: {<NNP>*|<DT>?<JJ>*<NN>}\n",
        "             PP: {<IN><NP>}\"\"\"\n",
        "\n",
        "# Parser\n",
        "cp = nltk.RegexpParser(grammar)\n",
        "result = cp.parse(sentence)\n",
        "\n",
        "# Output\n",
        "print(result)\n",
        "\n",
        "# Output tree\n",
        "svgling.draw_tree(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "yBXJh9d_xi-b",
        "outputId": "a0d85706-9e05-47dd-d425-50cdf34bffd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgling\n",
            "  Downloading svgling-0.3.1-py3-none-any.whl (21 kB)\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite, svgling\n",
            "Successfully installed svgling-0.3.1 svgwrite-1.4.3\n",
            "(S\n",
            "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
            "  barked/VBD\n",
            "  (PP at/IN (NP the/DT cat/NN))\n",
            "  (PP in/IN (NP New/NNP York/NNP)))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TreeLayout(Tree('S', [Tree('NP', [('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN')]), ('barked', 'VBD'), Tree('PP', [('at', 'IN'), Tree('NP', [('the', 'DT'), ('cat', 'NN')])]), Tree('PP', [('in', 'IN'), Tree('NP', [('New', 'NNP'), ('York', 'NNP')])])]))"
            ],
            "image/svg+xml": "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,504.0,216.0\" width=\"504px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"41.2698%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"19.2308%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.61538%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"30.7692%\" x=\"19.2308%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">little</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.6154%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"30.7692%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">yellow</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.3846%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"19.2308%\" x=\"80.7692%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">dog</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.3846%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.6349%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"12.6984%\" x=\"41.2698%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">barked</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"47.619%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"22.2222%\" x=\"53.9683%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"28.5714%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">at</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.2857%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"71.4286%\" x=\"28.5714%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cat</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.2857%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.0794%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.8095%\" x=\"76.1905%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"26.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.3333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"73.3333%\" x=\"26.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"45.4545%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">New</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.7273%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"54.5455%\" x=\"45.4545%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">York</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.7273%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.0952%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}